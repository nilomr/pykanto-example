{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "%matplotlib inline\n",
    "import git\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import neptune.new as neptune\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "# torch and lightning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from neptune.new.types import File\n",
    "from PIL import Image, ImageEnhance\n",
    "from pytorch_lightning.callbacks.finetuning import BaseFinetuning\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.utilities.rank_zero import rank_zero_info\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import _log_api_usage_once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure that all operations are deterministic for reproducibility\n",
    "seed = 42\n",
    "pl.seed_everything(seed)\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = (\n",
    "    torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class and method definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General-purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(spectrogram: np.ndarray, pad_length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Centre pads an RGB spectrogram to a given length.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (np.ndarray): Spectrogram to pad.\n",
    "        pad_length (int): Full length of padded spectrogram\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Padded spectrogram\n",
    "    \"\"\"\n",
    "    spec_shape = np.shape(spectrogram)\n",
    "    excess_needed = pad_length - spec_shape[1]\n",
    "    pad_left = int(np.floor(float(excess_needed) / 2))\n",
    "    pad_right = int(np.ceil(float(excess_needed) / 2))\n",
    "    padded_spec = np.full((spec_shape[0], pad_length, 3), np.min(spectrogram))\n",
    "    padded_spec[:, pad_left : pad_length - pad_right, :] = spectrogram\n",
    "    return padded_spec\n",
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data augmentation classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCrop(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Crops the given image at a random point in the time domain\n",
    "    greater than its height and smaller than its maximum\n",
    "    length minus its height.\n",
    "\n",
    "    Note:\n",
    "        Does not work with tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "        \"\"\"\n",
    "        img = np.asarray(img)\n",
    "        H, W = img.shape[:2]\n",
    "        if W < H:\n",
    "            # Pads adding some extra width\n",
    "            # so that the img is not always\n",
    "            # in the same position\n",
    "            img = pad(img, int(H + H * 0.25))\n",
    "\n",
    "        H, W = img.shape[:2]\n",
    "        r_idx = random.randint(0, W - H)\n",
    "        img = img[:, r_idx : r_idx + H]\n",
    "        return Image.fromarray(img)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "class ChangeBrightness(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Changes the brightness by a factor drawn from a uniform\n",
    "    distribution between provided numbers.\n",
    "\n",
    "    Args:\n",
    "        factor (tuple): A tuple containing a range of\n",
    "            brightness (e.g. 0.5 means 50% brightness).\n",
    "        p (float): Probability with which the\n",
    "            transformation will be applied.\n",
    "\n",
    "    Warning:\n",
    "        Does not work with tensors.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factor: tuple = (0.9, 1.6), p: float = 0.5):\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "        self.factor = factor\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be modified.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Modified image.\n",
    "        \"\"\"\n",
    "        if self.p < torch.rand(1):\n",
    "            return img\n",
    "        f = random.uniform(self.factor[0], self.factor[1])\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(f)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(factor={self.factor}, p={self.p})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/val/test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgTransform:\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size=224,\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "    ):\n",
    "        self.stage = {\n",
    "            \"train\": T.Compose(\n",
    "                [\n",
    "                    TimeCrop(),\n",
    "                    T.RandomRotation(degrees=(-2, 2)),\n",
    "                    T.RandomAdjustSharpness(sharpness_factor=6, p=0.2),\n",
    "                    T.GaussianBlur(kernel_size=(3, 3), sigma=(0.005, 4)),\n",
    "                    ChangeBrightness(factor=(0.8, 1.6), p=0.5),\n",
    "                    T.ToTensor(),\n",
    "                    # T.Normalize(mean, std),\n",
    "                    T.RandomErasing(\n",
    "                        p=0.2, scale=(0.02, 0.05), ratio=(0.3, 3.3)\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "            \"validate\": T.Compose(\n",
    "                [\n",
    "                    TimeCrop(),\n",
    "                    T.ToTensor(),\n",
    "                    # T.Normalize(mean, std),\n",
    "                ]\n",
    "            ),\n",
    "            \"test\": T.Compose(\n",
    "                [\n",
    "                    TimeCrop(),\n",
    "                    T.ToTensor(),\n",
    "                    # T.Normalize(mean, std),\n",
    "                ]\n",
    "            ),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreatTitDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path, test_path, batch_size=16, seed=42):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.seed = seed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Load and split training set\n",
    "        d = ImageFolder(self.train_path)\n",
    "\n",
    "        # Prepare weighted sampler for training data (oversample)\n",
    "        class_count = Counter(d.targets)\n",
    "        class_weights = torch.Tensor(\n",
    "            [\n",
    "                len(d.targets) / c\n",
    "                for c in pd.Series(class_count).sort_index().values\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        sample_weights = [0] * len(d)\n",
    "        for idx, (image, label) in enumerate(d):\n",
    "            class_weight = class_weights[label]\n",
    "            sample_weights[idx] = class_weight\n",
    "\n",
    "        self.train_sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights, num_samples=len(d), replacement=True\n",
    "        )\n",
    "\n",
    "        # Stratified split for validation\n",
    "        train_idx, valid_idx = train_test_split(\n",
    "            np.arange(len(d.targets)),\n",
    "            test_size=0.2,\n",
    "            shuffle=True,\n",
    "            random_state=self.seed,\n",
    "            stratify=d.targets,\n",
    "        )\n",
    "\n",
    "        # Prepare train/validation/test datasets\n",
    "        self.train, self.validate = copy(d), copy(d)\n",
    "        self.train.imgs = np.array(d.imgs)[train_idx].tolist()\n",
    "        self.train.targets = np.array(d.targets)[train_idx].tolist()\n",
    "        self.validate.imgs = np.array(d.imgs)[valid_idx].tolist()\n",
    "        self.validate.targets = np.array(d.targets)[valid_idx].tolist()\n",
    "        self.test = ImageFolder(self.test_path)\n",
    "\n",
    "        # Transforms\n",
    "        self.train.transform = ImgTransform().stage[\"train\"]\n",
    "        self.validate.transform = ImgTransform().stage[\"validate\"]\n",
    "        self.test.transform = ImgTransform().stage[\"test\"]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "            sampler=self.train_sampler,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validate,\n",
    "            batch_size=100,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=100,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See [1] for more details on the training regime:\n",
    "\n",
    "class MilestonesFinetuning(BaseFinetuning):\n",
    "    def __init__(self, milestones: tuple = (5, 10), train_bn: bool = False):\n",
    "        super().__init__()\n",
    "        self.milestones = milestones\n",
    "        self.train_bn = train_bn\n",
    "\n",
    "    def freeze_before_training(self, pl_module: pl.LightningModule):\n",
    "        self.freeze(modules=pl_module.feature_extractor, train_bn=self.train_bn)\n",
    "\n",
    "    def finetune_function(\n",
    "        self,\n",
    "        pl_module: pl.LightningModule,\n",
    "        epoch: int,\n",
    "        optimizer: Optimizer,\n",
    "        opt_idx: int,\n",
    "    ):\n",
    "        if epoch == self.milestones[0]:\n",
    "            # unfreeze 5 last layers\n",
    "            self.unfreeze_and_add_param_group(\n",
    "                modules=pl_module.feature_extractor[-5:],\n",
    "                optimizer=optimizer,\n",
    "                train_bn=self.train_bn,\n",
    "            )\n",
    "\n",
    "        elif epoch == self.milestones[1]:\n",
    "            # unfreeze remaining layers\n",
    "            self.unfreeze_and_add_param_group(\n",
    "                modules=pl_module.feature_extractor[:-5],\n",
    "                optimizer=optimizer,\n",
    "                train_bn=self.train_bn,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main model module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logg_params = {\n",
    "    \"on_step\": True,\n",
    "    \"on_epoch\": True,\n",
    "    \"prog_bar\": True,\n",
    "    \"logger\": True,\n",
    "}\n",
    "\n",
    "class ResNetClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int | None = None,\n",
    "        backbone: str = \"resnet50\",\n",
    "        train_bn: bool = False,\n",
    "        batch_size: int = 16,\n",
    "        transfer=True,\n",
    "        milestones: tuple = (2, 4),\n",
    "        lr: float = 1e-3,\n",
    "        lr_scheduler_gamma: float = 1e-1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.__dict__.update(locals())\n",
    "        self.num_classes = num_classes\n",
    "        self.backbone = backbone\n",
    "        self.transfer = transfer = (True,)\n",
    "        self.lr = lr\n",
    "        self.milestones = milestones\n",
    "        self.lr_scheduler_gamma = lr_scheduler_gamma\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.__build_model()\n",
    "\n",
    "        self.train_acc = Accuracy()\n",
    "        self.valid_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.val_confusion = ConfusionMatrix(num_classes=self.num_classes)\n",
    "        self.test_confusion = ConfusionMatrix(num_classes=self.num_classes)\n",
    "\n",
    "    def __build_model(self):\n",
    "        \"\"\"Define model layers & loss.\"\"\"\n",
    "\n",
    "        # 1. Load pre-trained network:\n",
    "        model_func = getattr(models, self.backbone)\n",
    "        self.backbone = model_func(pretrained=self.transfer)\n",
    "\n",
    "        _layers = list(self.backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*_layers)\n",
    "        linear_size = list(self.backbone.children())[-1].in_features\n",
    "\n",
    "        # 2. Classifier:\n",
    "        # _fc_layers = [nn.Linear(2048, 1000), nn.ReLU(), nn.Linear(1000, self.num_classes)]\n",
    "        # self.backbone.fc = nn.Sequential(*_fc_layers)\n",
    "        self.backbone.fc = nn.Linear(linear_size, self.num_classes)\n",
    "\n",
    "        # 3. Loss:\n",
    "        self.loss_func = (\n",
    "            nn.BCEWithLogitsLoss()\n",
    "            if self.num_classes == 2\n",
    "            else nn.CrossEntropyLoss()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        parameters = list(self.parameters())\n",
    "        trainab_params = list(filter(lambda p: p.requires_grad, parameters))\n",
    "        rank_zero_info(\n",
    "            f\"The model will start training with only {len(trainab_params)} \"\n",
    "            f\"trainable parameters out of {len(parameters)}.\"\n",
    "        )\n",
    "        optimizer = optim.Adam(trainab_params, lr=self.lr)\n",
    "        scheduler = MultiStepLR(\n",
    "            optimizer, milestones=self.milestones, gamma=self.lr_scheduler_gamma\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "\n",
    "        loss = self.loss_func(preds, y)\n",
    "        self.train_acc(preds, y)\n",
    "        self.log(\"train/loss\", loss, **logg_params)\n",
    "        self.log(\"train/acc\", self.train_acc, **logg_params)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "\n",
    "        loss = self.loss_func(preds, y)\n",
    "        self.train_acc(preds, y)\n",
    "        self.log(\"val/loss\", loss, **logg_params)\n",
    "        self.log(\"val/acc\", self.train_acc, **logg_params)\n",
    "        self.val_confusion.update(preds, batch[1])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "\n",
    "        loss = self.loss_func(preds, y)\n",
    "        self.test_acc(preds, y)\n",
    "        self.log(\"test/loss\", loss, **logg_params)\n",
    "        self.log(\"test/acc\", self.test_acc, **logg_params)\n",
    "        self.test_confusion.update(preds, batch[1])\n",
    "\n",
    "        # Save wrong prediction images\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = preds.argmax(axis=1).cpu().detach().numpy()\n",
    "\n",
    "        for j in np.where(np.not_equal(y_true, y_pred))[0]:\n",
    "            img = np.squeeze(x[j].cpu().detach().numpy())\n",
    "            img[img < 0] = 0\n",
    "            img = img / np.amax(img)\n",
    "            labs = list(\n",
    "                self.trainer.datamodule.val_dataloader().dataset.class_to_idx.keys()\n",
    "            )\n",
    "            neptune_logger.experiment[\"test/misclassified_images\"].log(\n",
    "                neptune.types.File.as_image(img.transpose((1, 2, 0))),\n",
    "                description=f\"y_pred = {labs[y_pred[j]]}, y_true = {labs[y_true[j]]}\",\n",
    "            )\n",
    "\n",
    "    # Output graphs and extra metrics\n",
    "    def plot_conf_matrix(self, conf_mat):\n",
    "        labs = (\n",
    "            self.trainer.datamodule.val_dataloader().dataset.class_to_idx.keys()\n",
    "        )\n",
    "        df_cm = pd.DataFrame(conf_mat, index=labs, columns=labs)\n",
    "        plt.figure(figsize=(13, 10))\n",
    "        fig_ = sns.heatmap(\n",
    "            df_cm, annot=True, cmap=\"magma\", fmt=\"g\"\n",
    "        ).get_figure()\n",
    "        plt.close(fig_)\n",
    "        return fig_\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        conf_mat = (\n",
    "            self.val_confusion.compute().detach().cpu().numpy().astype(np.int)\n",
    "        )\n",
    "        fig_ = self.plot_conf_matrix(conf_mat)\n",
    "        self.logger.experiment[\"train/confusion_matrix\"].log(\n",
    "            File.as_image(fig_)\n",
    "        )\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        conf_mat = (\n",
    "            self.test_confusion.compute().detach().cpu().numpy().astype(np.int)\n",
    "        )\n",
    "        fig_ = self.plot_conf_matrix(conf_mat)\n",
    "        self.logger.experiment[\"test/confusion_matrix\"].log(File.as_image(fig_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project settings/directories\n",
    "DATASET =  \"pykanto-example\"\n",
    "\n",
    "PROJECT_ROOT = Path(\n",
    "    git.Repo(\".\", search_parent_directories=True).working_tree_dir\n",
    ")\n",
    "\n",
    "data_path = PROJECT_ROOT / \"data\" / \"datasets\" / DATASET / \"ML\"\n",
    "train_path, test_path = data_path / \"train\", data_path / \"test\"\n",
    "n_classes = sum([1 for i in test_path.glob(\"**/\")]) - 1\n",
    "\n",
    "\n",
    "hparams = AttrDict(\n",
    "    {\n",
    "        \"batch_size\": 64,\n",
    "        \"num_classes\": n_classes,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr_scheduler_gamma\": 0.1,\n",
    "        \"milestones\": (10, 15),\n",
    "        \"transfer\": True,\n",
    "        \"train_bn\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "dm = GreatTitDataModule(\n",
    "    train_path=train_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=hparams.batch_size,\n",
    ")\n",
    "\n",
    "dm.setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start logger and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/nilomr/greti/e/GRET-72\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# To run this you will need neptune if you want to monitor model training,\n",
    "# see [2] for more details.\n",
    "\n",
    "# IMPORTANT: Load existing model? [None/model ID]\n",
    "use_existing = \"GRET-72\"\n",
    "\n",
    "\n",
    "def _init_neptune():\n",
    "    run = neptune.init(\n",
    "        project=\"nilomr/greti\",\n",
    "        flush_period=5,\n",
    "        with_id=use_existing,\n",
    "        mode=\"sync\",  # async won't work in Oxford HPC\n",
    "    )\n",
    "    return run\n",
    "\n",
    "def init_neptune_logger():\n",
    "    try:\n",
    "        return _init_neptune()\n",
    "    except:\n",
    "        try:\n",
    "            return _init_neptune()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "neptune_logger = NeptuneLogger(run=init_neptune_logger())\n",
    "\n",
    "CHECKPOINTS_DIR = Path(\"checkpoints\") / neptune_logger._run_short_id\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=CHECKPOINTS_DIR,\n",
    "    monitor=\"val/acc_epoch\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=2,\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = ResNetClassifier(**hparams)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    logger=neptune_logger,\n",
    "    callbacks=[\n",
    "        model_checkpoint,\n",
    "        EarlyStopping(monitor=\"val/loss_epoch\", mode=\"min\", patience=4),\n",
    "        MilestonesFinetuning(milestones=(5, 10), train_bn=hparams.train_bn),\n",
    "    ],\n",
    "    log_every_n_steps=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    precision=16, # If supported use 16-bit precision\n",
    "    num_sanity_val_steps=0,  #FIXME #BUG @nilomr Validation gets stuck with full dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model\n",
    "\n",
    "Skip this if you have already trained a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "The model will start training with only 2 trainable parameters out of 161.\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | backbone          | ResNet           | 23.7 M\n",
      "1 | feature_extractor | Sequential       | 23.5 M\n",
      "2 | loss_func         | CrossEntropyLoss | 0     \n",
      "3 | train_acc         | Accuracy         | 0     \n",
      "4 | valid_acc         | Accuracy         | 0     \n",
      "5 | test_acc          | Accuracy         | 0     \n",
      "6 | val_confusion     | ConfusionMatrix  | 0     \n",
      "7 | test_confusion    | ConfusionMatrix  | 0     \n",
      "-------------------------------------------------------\n",
      "174 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.7 M    Total params\n",
      "47.364    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e901d4a9c96543ea900b28ca4ba84391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NeptuneReporting:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/threading/daemon.py\", line 51, in run\n",
      "    self.work()\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/hardware/hardware_metric_reporting_job.py\", line 125, in work\n",
      "    attr.log(value=metric_value.value, timestamp=metric_value.timestamp)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 66, in inner_fun\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 276, in log\n",
      "    attr.log(value, step=step, timestamp=timestamp, wait=wait, **kwargs)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/series/series.py\", line 102, in log\n",
      "    self._enqueue_operation(op, wait)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/attribute.py\", line 41, in _enqueue_operation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._container._op_processor.enqueue_operation(operation, wait)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/operation_processors/sync_operation_processor.py\", line 36, in enqueue_operation\n",
      "    raise errors[0]\n",
      "neptune.new.exceptions.MetadataInconsistency: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-10-19T15:37:19.028Z\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NeptuneReporting:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/threading/daemon.py\", line 51, in run\n",
      "    self.work()\n",
      "Exception in thread NeptuneReporting  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/hardware/hardware_metric_reporting_job.py\", line 125, in work\n",
      ":\n",
      "    Traceback (most recent call last):\n",
      "attr.log(value=metric_value.value, timestamp=metric_value.timestamp)  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "\n",
      "      File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 66, in inner_fun\n",
      "self.run()    \n",
      "return fun(self, *args, **kwargs)  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/threading/daemon.py\", line 51, in run\n",
      "\n",
      "      File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 276, in log\n",
      "self.work()    \n",
      "attr.log(value, step=step, timestamp=timestamp, wait=wait, **kwargs)  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/hardware/hardware_metric_reporting_job.py\", line 125, in work\n",
      "\n",
      "      File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/series/series.py\", line 102, in log\n",
      "attr.log(value=metric_value.value, timestamp=metric_value.timestamp)    \n",
      "self._enqueue_operation(op, wait)  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 66, in inner_fun\n",
      "\n",
      "      File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/attribute.py\", line 41, in _enqueue_operation\n",
      "return fun(self, *args, **kwargs)    \n",
      "self._container._op_processor.enqueue_operation(operation, wait)  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 276, in log\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/operation_processors/sync_operation_processor.py\", line 36, in enqueue_operation\n",
      "attr.log(value, step=step, timestamp=timestamp, wait=wait, **kwargs)    \n",
      "raise errors[0]  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/series/series.py\", line 102, in log\n",
      "\n",
      "    neptune.new.exceptionsself._enqueue_operation(op, wait).\n",
      "MetadataInconsistency  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/attribute.py\", line 41, in _enqueue_operation\n",
      ":     Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-10-19T15:38:24.016Zself._container._op_processor.enqueue_operation(operation, wait)\n",
      "\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/operation_processors/sync_operation_processor.py\", line 36, in enqueue_operation\n",
      "    raise errors[0]\n",
      "neptune.new.exceptions.MetadataInconsistency: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-10-19T15:38:36.855Z\n",
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best model in held out (test) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_model = ResNetClassifier.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "# If from fresh session:\n",
    "\n",
    "lckpt = list(\n",
    "    (\n",
    "        Path(neptune_logger.save_dir).parent\n",
    "        / \"checkpoints\"\n",
    "        / neptune_logger._run_short_id\n",
    "    ).glob(\"*ckpt\")\n",
    ")[-1]\n",
    "best_model = ResNetClassifier.load_from_checkpoint(lckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565aa64d453c4be9b1da67bec1f9ae02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/acc_epoch         0.9215686321258545\n",
      "     test/loss_epoch        0.25644221901893616\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss_epoch': 0.25644221901893616,\n",
       "  'test/acc_epoch': 0.9215686321258545}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NeptuneReporting:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/threading/daemon.py\", line 51, in run\n",
      "    self.work()\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/hardware/hardware_metric_reporting_job.py\", line 125, in work\n",
      "    attr.log(value=metric_value.value, timestamp=metric_value.timestamp)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 66, in inner_fun\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/handler.py\", line 276, in log\n",
      "    attr.log(value, step=step, timestamp=timestamp, wait=wait, **kwargs)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/series/series.py\", line 102, in log\n",
      "    self._enqueue_operation(op, wait)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/attributes/attribute.py\", line 41, in _enqueue_operation\n",
      "    self._container._op_processor.enqueue_operation(operation, wait)\n",
      "  File \"/data/zool-songbird/shil5293/envs/pykanto-example/lib/python3.8/site-packages/neptune/new/internal/operation_processors/sync_operation_processor.py\", line 36, in enqueue_operation\n",
      "    raise errors[0]\n",
      "neptune.new.exceptions.MetadataInconsistency: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-10-20T09:26:11.884Z\n"
     ]
    }
   ],
   "source": [
    "trainer.test(best_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/loss': tensor(0.2564),\n",
       " 'test/loss_epoch': tensor(0.2564),\n",
       " 'test/acc': tensor(0.9216),\n",
       " 'test/acc_epoch': tensor(0.9216)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract feature vectors from the entire dataset\n",
    "\n",
    "Here we just use the training set for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb608dc25d441b29a32bbf952502523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e538230674c4b3f966f16b6e3d0e4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d840a50abbc644e6b7a67d4b0fb69c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360e27d0e2ad4121a761ea2fbebd6ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fd867903364e02b7f51f583f002fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgpaths = [i for i in train_path.glob(\"*/*.jpg\")]\n",
    "test_imgs = [i for i in test_path.glob(\"*/*.jpg\")]\n",
    "best_model.eval()\n",
    "best_model.to(device)\n",
    "vectors = {}\n",
    "\n",
    "# Test transformation includes random crop in the 'time' domain:\n",
    "# Running multiple times and averaging may increase robustness:\n",
    "niters = 5\n",
    "\n",
    "for i in range(niters):\n",
    "    vectors[str(i)] = {}\n",
    "    for path in tqdm(imgpaths, total=len(imgpaths)):\n",
    "        img = Image.open(path)\n",
    "        rgb_img = TimeCrop()(img)\n",
    "        tens_img = T.ToTensor()(rgb_img).unsqueeze_(0)\n",
    "        vectors[str(i)][f\"{path.stem}\"] = (\n",
    "            best_model.feature_extractor(tens_img.to(device))\n",
    "            .cpu()\n",
    "            .detach()\n",
    "            .numpy()[0, :, 0, 0]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldfs = pd.concat(\n",
    "    [pd.DataFrame.from_dict(d, orient='index') for d in vectors.values()])\n",
    "vocmean = alldfs.groupby(alldfs.index).mean()\n",
    "\n",
    "vector_dir = (PROJECT_ROOT / \"data\" / \"datasets\" / DATASET / 'ML' / \n",
    "       'output' / 'feat_vectors.csv')\n",
    "vector_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "vocmean.to_csv(vector_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "[1] https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/domain_templates/computer_vision_fine_tuning.py\n",
    "\n",
    "[2]\n",
    "https://docs.neptune.ai/integrations/lightning/ <br>\n",
    "https://docs.neptune.ai/usage/best_practices/#configuring-your-credentials"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0956b34faf254119b200338e019e5863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_324870f516de4da283471a6fe5cbf32d",
        "IPY_MODEL_1bc4477104cc495e91592b38610fd62c"
       ],
       "layout": "IPY_MODEL_9b7658f9bf944e5486a402ef9409843f"
      }
     },
     "18b2399586e34c0094b395fcf6dbdf67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bc4477104cc495e91592b38610fd62c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b52f0afe2cef4ddc85961d2136c0e77d",
       "placeholder": "​",
       "style": "IPY_MODEL_21f0010d16364031bad7198af2d6c07d",
       "value": " 12500/12500 [54:19&lt;00:00,  3.84it/s]"
      }
     },
     "21f0010d16364031bad7198af2d6c07d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "324870f516de4da283471a6fe5cbf32d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": " 90%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18b2399586e34c0094b395fcf6dbdf67",
       "max": 12500,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_90ad8398dccc4147a8c394802d87b394",
       "value": 11281
      }
     },
     "90ad8398dccc4147a8c394802d87b394": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9b7658f9bf944e5486a402ef9409843f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b52f0afe2cef4ddc85961d2136c0e77d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
